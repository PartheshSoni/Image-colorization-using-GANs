{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UBNIY0sWqXMg",
    "outputId": "b0c0f402-5116-4600-a36b-e0fffa8bd753"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "from keras.layers import Input,Dense,Reshape,Conv2D,Dropout,multiply,Dot,Concatenate,subtract,ZeroPadding2D\n",
    "from keras.layers import BatchNormalization,LeakyReLU,Flatten\n",
    "from keras.layers import Conv2DTranspose as Deconv2d\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from google.colab import files\n",
    "from keras import backend as K\n",
    "import smtplib\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from google.colab import drive\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRASEsOm1hPz"
   },
   "outputs": [],
   "source": [
    "def plot(A,B,C,n):\n",
    "\n",
    "    samples = [A,B,C]\n",
    "    fig = plt.figure(figsize=(3,n))\n",
    "    gs = gridspec.GridSpec(3,n)\n",
    "    g=0\n",
    "    for i in range(3):\n",
    "        for j in range(n):\n",
    "            ax = plt.subplot(gs[g])\n",
    "            g+=1\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            if samples[i][j].shape == (32,32,1):\n",
    "              plt.imshow(samples[i][j].reshape(32, 32))\n",
    "            else:\n",
    "              plt.imshow(samples[i][j].reshape(32,32,3))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1702nk3S3AI"
   },
   "outputs": [],
   "source": [
    "#for plotting any two images in case\n",
    "\n",
    "def ploty(A,B,n):\n",
    "\n",
    "    samples = [A,B]\n",
    "    fig = plt.figure(figsize=(3,n))\n",
    "    gs = gridspec.GridSpec(3,n)\n",
    "    g=0\n",
    "    for i in range(2):\n",
    "        for j in range(n):\n",
    "            ax = plt.subplot(gs[g])\n",
    "            g+=1\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            if samples[i][j].shape == (32,32,1):\n",
    "              plt.imshow(samples[i][j].reshape(32, 32, 1))\n",
    "            else:\n",
    "              plt.imshow(samples[i][j].reshape(32,32,3))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "N68yNhL9z3jr",
    "outputId": "649b9c8d-d8c2-4e05-ee0c-5fa46e638eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "btWe5_6_y5tr",
    "outputId": "1f76e6c2-c461-42d4-e856-5c526defed96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "(50000, 32, 32, 1)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y=x_train\n",
    "x=np.sum(y, axis=3)/(3*255)\n",
    "\n",
    "y_test=x_test\n",
    "x_test=np.sum(x_test, axis=3)/(3*255)   #for converting RGB into singe channel\n",
    "x_test=x_test.reshape(10000, 32, 32, 1)\n",
    "\n",
    "\n",
    "y=x_train/255\n",
    "y=y*2-1\n",
    "\n",
    "\n",
    "#x=x*2-1\n",
    "#x=np.dot(y[...,:3], [0.299, 0.587, 0.114])/255\n",
    "#x=x.reshape(50000,32, 32,1)\n",
    "\n",
    "x=x.reshape(50000, 32, 32, 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maALbVf-qmm0"
   },
   "outputs": [],
   "source": [
    "  \n",
    "x_shape=(32,32,1)\n",
    "y_shape=(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwbiitZCqo7r"
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "  X = Input(shape = x_shape)\n",
    "  \n",
    "  #C1 = ZeroPadding2D(padding=(1,1))(X)  \n",
    "  C1 = Conv2D(64,kernel_size = 1, strides = 1,input_shape = x_shape)(X)\n",
    "  C1 = LeakyReLU(0.2)(C1)\n",
    "  \n",
    "  C2 = Conv2D(128,kernel_size = 2, strides = 2)(C1)  \n",
    "  C2 = LeakyReLU(0.2)(C2)\n",
    "  \n",
    "  C3 = Conv2D(256,kernel_size = 2, strides = 2)(C2)\n",
    "  C3 = LeakyReLU(0.2)(C3)\n",
    "  \n",
    "  C4 = Conv2D(512,kernel_size = 2, strides = 2)(C3)\n",
    "  C4 = LeakyReLU(0.2)(C4)\n",
    "\n",
    "  C5 = Conv2D(512, kernel_size = 2, strides = 2)(C4)\n",
    "  C5 = LeakyReLU(0.2)(C5)\n",
    "  \n",
    "  \n",
    "  DC0 = Deconv2d(512, kernel_size = 2, strides = 2)(C5)\n",
    "  DC0 = LeakyReLU(0.2)(DC0)\n",
    "  DC0 = BatchNormalization()(DC0)\n",
    "  DC0 = Dropout(0.5)(DC0)\n",
    "  DC0 = Concatenate(axis=3)([DC0, C4])\n",
    "\n",
    "  \n",
    "  DC1 = Deconv2d(256,kernel_size=2, strides = 2)(DC0)\n",
    "  DC1 = LeakyReLU(0.2)(DC1)\n",
    "  DC1 = BatchNormalization()(DC1)  \n",
    "  DC1 = Dropout(0.5)(DC1)             \n",
    "  DC1 = Concatenate(axis=3)([DC1,C3])\n",
    "\n",
    "  \n",
    "  DC2 = Deconv2d(128,kernel_size=2, strides = 2)(DC1)\n",
    "  DC2 = LeakyReLU(0.2)(DC2)\n",
    "  DC2 = BatchNormalization()(DC2)  \n",
    "  DC2 = Concatenate(axis=3)([DC2,C2])\n",
    "  \n",
    "  DC3 = Deconv2d(64,kernel_size=2, strides = 2)(DC2)\n",
    "  DC3 = LeakyReLU(0.2)(DC3)\n",
    "  DC3 = BatchNormalization()(DC3)  \n",
    "  DC3 = Concatenate(axis=3)([DC3,C1])\n",
    "  \n",
    "  #DC4 = ZeroPadding2D(padding=(3,1))(DC3)  \n",
    "  CC4 = Conv2D(3,kernel_size=(1, 1), strides = (1, 1), activation=\"tanh\")(DC3)\n",
    "  \n",
    "  m = Model(X,CC4)\n",
    "  #m.summary()\n",
    "  return m\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4X4dnGFqtKb"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  X = Input(shape = x_shape)\n",
    "  Y = Input(shape = y_shape)\n",
    "  \n",
    "  In = Concatenate(axis=3)([X,Y])\n",
    "  \n",
    "  C1 = Conv2D(64,kernel_size = 2, strides = 2,input_shape = x_shape)(In)\n",
    "  C1 = BatchNormalization()(C1)\n",
    "  C1 = LeakyReLU(0.2)(C1)\n",
    "  C2 = Conv2D(128,kernel_size = 2, strides = 2)(C1)  \n",
    "  C2 = BatchNormalization()(C2)\n",
    "  C2 = LeakyReLU(0.2)(C2)\n",
    "  \n",
    "  C3 = Conv2D(256,kernel_size = 2, strides = 2)(C2)\n",
    "  C3 = BatchNormalization()(C3)\n",
    "  C3 = LeakyReLU(0.2)(C3)\n",
    "  \n",
    "  C4 = Conv2D(512,kernel_size = 1, strides = 1)(C3)\n",
    "  C4 = BatchNormalization()(C4)\n",
    "  C4 = LeakyReLU(0.2)(C4)\n",
    "  \n",
    "  D = Flatten()(C4)\n",
    "  D = Dense(128)(D)\n",
    "  D = Dense(1,activation='sigmoid')(D)\n",
    "  \n",
    "  m = Model([X,Y],D)\n",
    "  #m.summary()\n",
    "  return m\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2312
    },
    "colab_type": "code",
    "id": "DSmYt36HqvHi",
    "outputId": "7a027ccc-f0e7-457b-e1e2-4eeef05714b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 10:55:12.498533 140035382265728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0624 10:55:12.537317 140035382265728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0624 10:55:12.551486 140035382265728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0624 10:55:12.693056 140035382265728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0624 10:55:12.694570 140035382265728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0624 10:55:15.860692 140035382265728 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0624 10:55:15.963212 140035382265728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 128)  32896       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 256)    131328      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 256)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 512)    524800      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 4, 4, 512)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 2, 512)    1049088     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 2, 2, 512)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 512)    1049088     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 512)    0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4, 4, 512)    2048        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 1024)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 256)    1048832     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 256)    0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 256)    1024        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 512)    0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 16, 16, 128)  262272      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 64)   65600       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 3)    387         concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,168,259\n",
      "Trainable params: 4,166,339\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 4)    0           input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   1088        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 128)    32896       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 256)    131328      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 4, 4, 256)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 512)    131584      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8192)         0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          1048704     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,349,569\n",
      "Trainable params: 1,347,649\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = Input(shape = x_shape)\n",
    "Y = Input(shape = y_shape)\n",
    "\n",
    "gen = Generator()\n",
    "dis = Discriminator()\n",
    "\n",
    "out = gen(X)\n",
    "comb = dis([X,out])\n",
    "\n",
    "out = Flatten()(out)\n",
    "org = Flatten()(Y)\n",
    "\n",
    "cos_dis = Dot(axes = 1,normalize = True)([out,org])\n",
    "\n",
    "combined = Model([X,Y],[comb,cos_dis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aEF_YjzLI9l"
   },
   "outputs": [],
   "source": [
    "genLoss=[]\n",
    "disLoss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C005zvKC1VGD"
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch_size = 50\n",
    "n_example = 50000\n",
    "batches = int(n_example/batch_size)\n",
    "dis_updates = 2\n",
    "gen_updates = 1\n",
    "zero=np.zeros((batch_size,1))\n",
    "one=np.ones((batch_size,1))*0.9\n",
    "d_loss_factor = batches*2*dis_updates\n",
    "g_loss_factor = batches*gen_updates\n",
    "reuse = False\n",
    "adams = Adam(lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itR-uzoRVq_C"
   },
   "outputs": [],
   "source": [
    "#location in drive where models are present.\n",
    "\n",
    "if(reuse == True):\n",
    "  gen.load_weights(\"gdrive/My Drive/newGAN/Generator.h5\")\n",
    "  dis.load_weights(\"gdrive/My Drive/newGAN/Discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ffMSHzQq16E"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "  print(\"##############\")\n",
    "  print(\"For Epoch:\"+str(epoch))\n",
    "  \n",
    "  g_loss = 0\n",
    "  d_loss = 0\n",
    "  \n",
    "  print(\"Training Discriminator\")\n",
    "  \n",
    "  i = shuffle(range(n_example))\n",
    "  \n",
    "  dis.trainable = True\n",
    "  dis.compile(loss = \"binary_crossentropy\",optimizer = adams)\n",
    "  \n",
    "  for j in range(dis_updates):\n",
    "      \n",
    "    for b in range(batches):\n",
    "        \n",
    "      x_batch = x[i[b*batch_size:(b+1)*batch_size]]\n",
    "      y_batch = y[i[b*batch_size:(b+1)*batch_size]]\n",
    "      \n",
    "      pre_batch = gen.predict(x_batch)\n",
    "      \n",
    "      d_loss += dis.train_on_batch([x_batch,y_batch],one)\n",
    "      d_loss += dis.train_on_batch([x_batch,pre_batch],zero)\n",
    "      \n",
    "  print(\"Training Generator\")\n",
    "  \n",
    "  dis.trainable = False\n",
    "  combined.compile(loss  = \"binary_crossentropy\", optimizer = adams)  \n",
    "  dis.compile(loss = \"binary_crossentropy\",optimizer = adams)\n",
    "        \n",
    "  for  j in range(gen_updates):\n",
    "    \n",
    "    for b in range(batches):\n",
    "      \n",
    "      x_batch = x[i[b*batch_size:(b+1)*batch_size]]\n",
    "      y_batch = y[i[b*batch_size:(b+1)*batch_size]]\n",
    "      \n",
    "        \n",
    "      #in case the mode collapse takes place....commenting next two lines might help.\n",
    "      #if b%4==3:\n",
    "        #gl,_,_ = combined.train_on_batch([x_batch,y_batch],[zero,one])  \n",
    "      \n",
    "      gl,_,_ = combined.train_on_batch([x_batch,y_batch],[one,one])\n",
    "      g_loss += gl\n",
    "      \n",
    "  g_loss /= g_loss_factor\n",
    "  d_loss /= d_loss_factor\n",
    "      \n",
    "  print(\"Discriminator Loss:\"+str(d_loss))\n",
    "  print(\"Generator loss:\"+str(g_loss))\n",
    "  \n",
    "  genLoss.append(g_loss)\n",
    "  disLoss.append(d_loss)\n",
    "  \n",
    "  gen.save_weights(\"gdrive/My Drive/newGAN/Generator.h5\")\n",
    "  dis.save_weights(\"gdrive/My Drive/newGAN/Discriminator.h5\")\n",
    "  \n",
    "\n",
    "\n",
    "  plt_indices = np.random.randint(50000,size=3)\n",
    "  plt_a = x[plt_indices]\n",
    "  plt_b = gen.predict(plt_a)\n",
    "  plt_b = (plt_b+1)/2\n",
    "  plt_c = (y[plt_indices]+1)/2\n",
    "  fig = plot(plt_a,plt_b,plt_c,3)\n",
    "  plt.show()\n",
    "  plt.close(fig)\n",
    " \n",
    "\n",
    "\n",
    "plt.plot(genLoss, c='r', label=\"Generator Loss\")\n",
    "plt.plot(disLoss, c='b', label=\"Discriminator Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "files.download('gdrive/My Drive/GANModels/Generator.h5')\n",
    "files.download('gdrive/My Drive/GANModels/Discriminator.h5')\n",
    "\n",
    "\n",
    "\n",
    "#for recieving mail on completion of training.\n",
    "server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "server.starttls()\n",
    "server.login(\"************@gmail.com\", \"*********\")\n",
    " \n",
    "msg = \"COLAB WORK FINISH ALERT!\"\n",
    "server.sendmail(\"***********@gmail.com\", \"********@nirmauni.ac.in\", msg)\n",
    "server.quit()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GANForProject.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
